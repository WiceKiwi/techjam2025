data:
  train_path: "datasets/splits/train.jsonl"      # replace with your train split path
  val_path:   "datasets/splits/val.jsonl"        # replace with your val split path
  test_path:  "datasets/splits/test.jsonl"       # replace with your test split path

schema:
  id_key: "review_id"
  group_key: "gmap_id"

# Split targets by task
targets:
  binary: ["ads_promo", "spam_low_quality", "irrelevant", "rant_no_visit"]
  regression: ["relevancy_score", "visit_likelihood"]

features:
  mode: "auto_numeric"       # or "explicit" + include: [...]
  exclude: ["review_id", "gmap_id", "user_id", "text"]

thresholding:
  strategy: "fixed"        # or "fixed"
  fixed: {"ads_promo": 0.6, "spam_low_quality": 0.6, "irrelevant": 0.9, "rant_no_visit": 0.6}                  # e.g., {"ads_promo": 0.6, ...}

model:
  type: "lgbm"
  binary:
    class_weight: "balanced" # helps rare classes
    params:
      num_leaves: 31
      max_depth: -1
      learning_rate: 0.05
      n_estimators: 800
      subsample: 0.9
      colsample_bytree: 0.9
      min_child_samples: 20
      reg_alpha: 0.0
      reg_lambda: 0.0
      random_state: 16
  regression:
    params:
      num_leaves: 31
      max_depth: -1
      learning_rate: 0.05
      n_estimators: 800
      subsample: 0.9
      colsample_bytree: 0.9
      min_child_samples: 20
      reg_alpha: 0.0
      reg_lambda: 0.0
      random_state: 16
  calibration:
    enabled: true
    method: "isotonic" # "isotonic" (best) or "sigmoid"
    cv: "prefit" # prefit on val

train:
  drop_na_targets: true
  early_stopping_rounds: 50  # uses val set

output:
  dir: "artifacts/models"                        # choose your models output dir
  metrics_json: "artifacts/models/metrics.json"  # where to write metrics
  thresholds_json: "artifacts/models/thresholds.json"  # written by training; replace if stored elsewhere
  preds_val: "artifacts/preds/val_preds.jsonl"   # where to write validation preds
  preds_test: "artifacts/preds/test_preds.jsonl" # where to write test preds
